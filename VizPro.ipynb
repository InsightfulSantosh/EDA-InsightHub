{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEIoA/zw8gZUliHvyp1tQP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InsightfulSantosh/EDA-InsightHub/blob/main/VizPro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "WqeT-0kDHvf2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from sklearn.preprocessing import (\n",
        "    PowerTransformer,\n",
        "    OneHotEncoder,\n",
        "    StandardScaler\n",
        ")\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from IPython.display import display, HTML"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adjust font size\n",
        "\n",
        "def display_html(size=3, content=\"content\"):\n",
        "    \"\"\"\n",
        "    Generates and displays an HTML header of specified size and content.\n",
        "\n",
        "    Parameters:\n",
        "    - size (int): The header size (1 for <h1>, 2 for <h2>, etc.). Default is 3.\n",
        "    - content (str): The text content to display within the header. Default is \"content\".\n",
        "\n",
        "    Returns:\n",
        "    - None: The function directly renders the HTML header in the output.\"\"\"\n",
        "    display(HTML(f\"<h{size}>{content}</h{size}>\"))\n"
      ],
      "metadata": {
        "id": "2TSsexVDH2gB"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display misisng info:\n",
        "def missing_info(df):\n",
        "    \"\"\"\n",
        "    Identifies and summarizes missing data in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): The input DataFrame to analyze.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: A DataFrame with columns 'column', 'count', and 'percentage'\n",
        "      indicating the column name, the number of missing values, and the percentage\n",
        "      of missing values, respectively, sorted by the count of missing values in descending order.\n",
        "    \"\"\"\n",
        "    na_col = [col for col in df.columns if df[col].isna().any()]\n",
        "    missing_data = pd.DataFrame({\n",
        "        \"column\": na_col,\n",
        "        \"count\": df[na_col].isna().sum(),\n",
        "        \"percentage\": df[na_col].isna().sum() / df.shape[0] * 100\n",
        "    }).sort_values(by=\"count\", ascending=False).set_index(\"column\").reset_index()\n",
        "    return missing_data\n",
        "\n",
        "def plot_missing_info(data,rotation=45, figsize=(10, 4)):\n",
        "    \"\"\"\n",
        "    Plots the count of missing values for each variable in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - data (pd.DataFrame): The input DataFrame to analyze.\n",
        "    - rotation (int): The rotation angle for x-axis labels. Default is 45 degrees.\n",
        "    - figsize (tuple): The size of the figure. Default is (10, 4).\n",
        "\n",
        "    Returns:\n",
        "    - None: The function displays a bar plot showing the count of missing values per variable.\n",
        "    \"\"\"\n",
        "    na_data = missing_info(data)\n",
        "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
        "\n",
        "    # Create the bar plot with proper x-axis labels\n",
        "    bar = ax.bar(\n",
        "        range(len(na_data)),\n",
        "        height=na_data[\"count\"].values,\n",
        "        color=\"#1eba47\",\n",
        "        edgecolor=\"black\",\n",
        "        tick_label=na_data['column'],  # to use column names\n",
        "        alpha=0.7\n",
        "    )\n",
        "    # Set axis labels and title\n",
        "    ax.set(\n",
        "        xlabel=\"Variable\",\n",
        "        ylabel=\"Count\",\n",
        "        title=\"Missing Data Counts per Variable\"\n",
        "    )\n",
        "\n",
        "    # Rotate x-axis labels if needed\n",
        "    plt.xticks(rotation=rotation)\n",
        "\n",
        "    # Adjust layout and display the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-AiXzFShI2jH"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IsolationForest for outlier detection\n",
        "def outlier_detect(df):\n",
        "    \"\"\"\n",
        "    Detects outliers in a DataFrame using the IsolationForest algorithm.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): The input DataFrame to analyze. Only numeric columns are considered for outlier detection.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: A DataFrame containing the rows identified as outliers. An additional column 'ouliers' is added with a value of -1 for outliers.\n",
        "    \"\"\"\n",
        "    isl= IsolationForest(n_estimators=50,random_state=42)\n",
        "    outlier=df.assign(ouliers=isl.fit_predict(df.iloc[:, :-1]\n",
        "                .select_dtypes(include=\"number\"))).query(\"ouliers==-1\")\n",
        "    return outlier\n"
      ],
      "metadata": {
        "id": "MnxjKTROI3nZ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IQR for outlier detection\n",
        "def get_iqr_outliers(data, var, band=1.5):\n",
        "    \"\"\"\n",
        "    Detects outliers in a DataFrame using the Interquartile Range (IQR) method.\n",
        "\n",
        "    Parameters:\n",
        "    - data (pd.DataFrame): The input DataFrame containing the variable to analyze.\n",
        "    - var (str): The name of the column/variable for which to detect outliers.\n",
        "    - band (float): The multiplier for the IQR to determine the lower and upper limits. Default is 1.5.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: A DataFrame containing the rows identified as outliers, sorted by the variable `var`.\n",
        "    \"\"\"\n",
        "    q1, q3 = (\n",
        "        data\n",
        "        .loc[:, var]\n",
        "        .quantile([0.25, 0.75])\n",
        "        .values\n",
        "    )\n",
        "\n",
        "    iqr = q3 - q1\n",
        "    lower_limit = q1 - (band * iqr)\n",
        "    upper_limit = q3 + (band * iqr)\n",
        "\n",
        "    display_html(3, f\"{var} - IQR Limits:\")\n",
        "    print(f\"{'Lower Limit':12}: {lower_limit}\")\n",
        "    print(f\"{'Upper Limit':12}: {upper_limit}\")\n",
        "\n",
        "    outliers = data.query(f\"{var} > @upper_limit | {var} < @lower_limit\")\n",
        "    display_html(3, f\"Total outliers detected: {outliers.shape[0]}\")\n",
        "\n",
        "    return outliers.sort_values(var)"
      ],
      "metadata": {
        "id": "FMZxLV0WJCbg"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pair plot\n",
        "def pair_plots(data,\n",
        "               height=3,\n",
        "               aspect=1.5,\n",
        "               hue=None,\n",
        "               legend=False):\n",
        "    \"\"\"\n",
        "    Generates pair plots (scatterplots) for the given DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - data (pd.DataFrame): The input DataFrame containing the data to plot.\n",
        "    - height (float): The height of each plot in the grid. Default is 3.\n",
        "    - aspect (float): The aspect ratio of each plot (width/height). Default is 1.5.\n",
        "    - hue (str or None): Variable in `data` to map plot aspects to different colors. Default is None.\n",
        "    - legend (bool): Whether to add a legend to the plots. Default is False.\n",
        "\n",
        "    Returns:\n",
        "    - None: The function displays a grid of pair plots.\n",
        "    \"\"\"\n",
        "    display_html(2, \"Pair Plots\")\n",
        "\n",
        "    pair_grid = sns.PairGrid(\n",
        "        data=data,\n",
        "        aspect=aspect,\n",
        "        height=height,\n",
        "        hue=hue,\n",
        "        corner=True\n",
        "    )\n",
        "    pair_grid.map_lower(sns.scatterplot)\n",
        "\n",
        "    if legend:\n",
        "        pair_grid.add_legend()"
      ],
      "metadata": {
        "id": "LvoAiLzRJL2c"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Corelation analysis of numerical variable\n",
        "def corr_heatmap(df, method=\"spearman\",cmap='coolwarm', figsize=(8, 6)):\n",
        "    \"\"\"\n",
        "    Generates a correlation heatmap for numerical variables in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): The input DataFrame containing the data for correlation analysis.\n",
        "    - method (str): The correlation method to use. Options include 'pearson', 'kendall', and 'spearman'. Default is 'spearman'.\n",
        "    - cmap (str): The colormap to use for the heatmap. Default is 'coolwarm'.\n",
        "    - figsize (tuple): The size of the figure (width, height) in inches. Default is (8, 6).\n",
        "\n",
        "    Returns:\n",
        "    - None: The function displays a heatmap of the correlation matrix.\n",
        "    \"\"\"\n",
        "    # Compute the correlation matrix\n",
        "    cm = df.corr(method=method, numeric_only=True)\n",
        "\n",
        "    # Create a mask for the upper triangle\n",
        "    mask = np.zeros_like(cm, dtype=bool)\n",
        "    mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "    # Create the figure and axis\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "    # Create the heatmap\n",
        "    sns.heatmap(cm, annot=True, mask=mask, ax=ax, cmap=cmap, vmin=-1, vmax=1)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.yticks(rotation=45)\n",
        "    ax.set(title= f\"{method.title()} Correlation Matrix Heatmap\")\n",
        "    # Display the plot\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Y6BjCX1WJZdN"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Corelation analysis of categorical variable\n",
        "def cramers_heatmap(df, cmap='coolwarm', figsize=(8, 6)):\n",
        "    \"\"\"\n",
        "    Generates a Cramér's V correlation heatmap for categorical variables in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): The input DataFrame containing the categorical data for correlation analysis.\n",
        "    - cmap (str): The colormap to use for the heatmap. Default is 'coolwarm'.\n",
        "    - figsize (tuple): The size of the figure (width, height) in inches. Default is (8, 6).\n",
        "\n",
        "    Returns:\n",
        "    - None: The function displays a heatmap of the Cramér's V correlation matrix.\n",
        "\n",
        "    Example:\n",
        "    cramers_heatmap(df, cmap=\"viridis\", figsize=(10, 8))\n",
        "    \"\"\"\n",
        "    # Get categorical columns\n",
        "    cat_cols = df.select_dtypes(include='object').columns\n",
        "    # Initialize a DataFrame for the correlation matrix\n",
        "    cramers_v_matrix = pd.DataFrame(index=cat_cols, columns=cat_cols)\n",
        "\n",
        "    # Compute Cramér's V for each pair of categorical columns\n",
        "    for i in cat_cols:\n",
        "        for j in cat_cols:\n",
        "            if i == j:\n",
        "                cramers_v_matrix.loc[i, j] = 1.0  # Diagonal should be 1.0\n",
        "            else:\n",
        "                cramers_v_matrix.loc[i, j] = cramers_v(df, i, j)\n",
        "\n",
        "    # Convert the Cramér's V matrix to numeric type\n",
        "    cramers_v_matrix = cramers_v_matrix.astype(float)\n",
        "\n",
        "    # Create a mask for the upper triangle\n",
        "    mask = np.zeros_like(cramers_v_matrix, dtype=bool)\n",
        "    mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "    # Plot heatmap\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    sns.heatmap(\n",
        "        cramers_v_matrix,\n",
        "        vmin=0,\n",
        "        vmax=1,\n",
        "        cmap=cmap,\n",
        "        annot=True,\n",
        "        fmt=\".2f\",\n",
        "        square=True,\n",
        "        linewidths=1.5,\n",
        "        mask=mask,\n",
        "        ax=ax\n",
        "    )\n",
        "    ax.set(title=\"Cramer's V Correlation Matrix Heatmap\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.yticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "z_obUdjwJjeN"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of categorical variables:\n",
        "def cat_summary(df, var):\n",
        "    \"\"\"\n",
        "    Generates a summary report for a categorical variable in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): The input DataFrame containing the categorical data.\n",
        "    - var (str): The name of the categorical variable to summarize.\n",
        "\n",
        "    Returns:\n",
        "    - None: The function displays various statistics and information about the specified categorical variable, including:\n",
        "        - A quick glance at the data in the variable.\n",
        "        - Metadata such as data type, cardinality (number of unique values), and missing data information.\n",
        "        - Summary statistics.\n",
        "        - Distribution of categories in terms of count and percentage.\n",
        "    \"\"\"\n",
        "    # Extract the column specified by 'var' from the DataFrame 'df'\n",
        "    col = df.loc[:, var].copy()\n",
        "\n",
        "    # Display the variable name as a header\n",
        "    display_html(3, var)\n",
        "\n",
        "    # Display a quick glance at the column\n",
        "    display_html(3, \"Quick Glance:\")\n",
        "    print(col)\n",
        "\n",
        "    # Display metadata about the column\n",
        "    display_html(3, \"Meta-data:\")\n",
        "    print(f\"Datatype:       {col.dtype}\")  # Data type of the column\n",
        "    print(f\"Cardinality:    {col.nunique(dropna=True)}\")  # Number of unique values (excluding NaN)\n",
        "    print(f\"Missing data:   {col.isna().sum()} rows ({col.isna().sum()/df.shape[0]:.2%})\")  # Missing values count and percentage\n",
        "    print(f\"Available data: {(~col.isna()).sum()} / {col.shape[0]}\")  # Available data count\n",
        "\n",
        "    # Display summary statistics of the column\n",
        "    display_html(3, \"Summary:\")\n",
        "    display(col.describe().rename(\"\").to_frame())  # Summary statistics for numeric columns\n",
        "\n",
        "    # Display category distribution\n",
        "    display_html(3, \"Categories Distribution:\")\n",
        "    with pd.option_context(\"display.max_rows\", None):\n",
        "        # Create a DataFrame with count and percentage of each category\n",
        "        display(pd.DataFrame({\"count\": col.value_counts(),\n",
        "                              \"percentage\": (col.value_counts() / col.shape[0])*100})\n",
        "                .rename_axis(index=\"category\"))\n"
      ],
      "metadata": {
        "id": "b4tGjmvYKC-b"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of Numerical variables:\n",
        "\n",
        "def Num_summary(df, var):\n",
        "    \"\"\"\n",
        "    Generates a detailed summary report for a numerical variable in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): The input DataFrame containing the numerical data.\n",
        "    - var (str): The name of the numerical variable to summarize.\n",
        "\n",
        "    Returns:\n",
        "    - None: The function displays various statistics and information about the specified numerical variable, including:\n",
        "        - A quick glance at the data in the variable.\n",
        "        - Metadata such as data type, missing data information, and available data count.\n",
        "        - Percentiles, including the 0th, 5th, 10th, 25th, 50th (median), 75th, 90th, 95th, 99th, and 100th percentiles.\n",
        "        - Central tendency measures like mean, trimmed mean (5% and 10%), and median.\n",
        "        - Measures of spread such as variance, standard deviation, interquartile range (IQR), median absolute deviation (MAD),\n",
        "        and coefficient of variation.\n",
        "        - Skewness and kurtosis.\n",
        "        - Hypothesis testing for normality.\"\"\"\n",
        "    # Extract the column specified by 'var' from the DataFrame 'df'\n",
        "    col = df.loc[:, var].copy()\n",
        "\n",
        "    # Display the variable name as a header\n",
        "    display_html(3, var)\n",
        "\n",
        "    # Display a quick glance at the column\n",
        "    display_html(3, \"Quick Glance:\")\n",
        "    print(col)\n",
        "\n",
        "    # Display metadata about the column\n",
        "    display_html(3, \"Meta-data:\")\n",
        "    print(f\"Datatype:       {col.dtype}\")  # Data type of the column\n",
        "    print(f\"Missing data:   {col.isna().sum()} rows ({col.isna().sum()/df.shape[0]:.2%})\")  # Missing values count and percentage\n",
        "    print(f\"Available data: {(~col.isna()).sum()} / {col.shape[0]}\")  # Available data count\n",
        "\n",
        "    #Percentile\n",
        "    display_html(3, \"Percentiles:\")\n",
        "    display(col\n",
        "        .quantile([0.0, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99, 1.0])\n",
        "        .reset_index().rename(columns={\"index\":\"percentile\",var:\"value\"})\n",
        "        .assign(percentile=(lambda x: x[\"percentile\"]*100)) # Multiply only the 'percentile' column by 100\n",
        "        .set_index('percentile')\n",
        "        )\n",
        "    # central tendancy\n",
        "    display_html(3, \"Central Tendancy:\")\n",
        "    display(\n",
        "        pd\n",
        "        .Series({\"mean\": col.mean(),\n",
        "                \"trimmed mean (5%)\": stats.trim_mean(col.values, 0.05),\n",
        "                \"trimmed mean (10%)\": stats.trim_mean(col.values, 0.1),\n",
        "                \"median\": col.median()})\n",
        "        .rename(\"value\")\n",
        "        .to_frame()\n",
        "        )\n",
        "    # spread\n",
        "    display_html(3, \"Measure of Spread:\")\n",
        "    std = col.std()\n",
        "    iqr = col.quantile(0.75) - col.quantile(0.25)\n",
        "    display(\n",
        "        pd\n",
        "        .Series({\n",
        "            \"var\": col.var(),\n",
        "            \"std\": std,\n",
        "            \"IQR\": iqr,\n",
        "            \"mad\": stats.median_abs_deviation(col.dropna()),\n",
        "            \"coef_variance\": std / col.mean()\n",
        "        })\n",
        "        .rename(\"value\")\n",
        "        .to_frame()\n",
        "    )\n",
        "\n",
        "    # skewness and kurtosis\n",
        "    display_html(3, \"Skewness and Kurtosis:\")\n",
        "    display(\n",
        "        pd\n",
        "        .Series({\n",
        "            \"skewness\": col.skew(),\n",
        "            \"kurtosis\": col.kurtosis()\n",
        "        })\n",
        "        .rename(\"value\")\n",
        "        .to_frame()\n",
        "    )\n",
        "    alpha = 0.05\n",
        "    # test for normality\n",
        "    display_html(3, \"Hypothesis Testing for Normality:\")\n",
        "    # shapiro-wilk test\n",
        "    display_html(4, \"Shapiro-Wilk Test:\")\n",
        "    sw_test = stats.shapiro(col.dropna().sample(4500).values)\n",
        "    sw_statistic = sw_test.statistic\n",
        "    sw_pvalue = sw_test.pvalue\n",
        "    print(f\"{'Significance Level':21}: {alpha}\")\n",
        "    print(f\"{'Null Hypothesis':21}: The data is normally distributed\")\n",
        "    print(f\"{'Alternate Hypothesis':21}: The data is not normally distributed\")\n",
        "    print(f\"{'p-value':21}: {sw_pvalue}\")\n",
        "    print(f\"{'Test Statistic':21}: {sw_statistic}\")\n",
        "    if sw_pvalue < alpha:\n",
        "        print(f\"- Since p-value is less than alpha ({alpha}), we Reject the Null Hypothesis at {alpha * 100}% significance level\")\n",
        "        print(\"- CONCLUSION: We conclude that the data sample is not normally distributed\")\n",
        "    else:\n",
        "        print(f\"- Since p-value is greater than alpha ({alpha}), we Fail to Reject the Null Hypothesis at {alpha * 100}% significance level\")\n",
        "        print(\"- CONCLUSION: We conclude that the data sample is normally distributed\")\n",
        "\n",
        "    #anderson-darling test\n",
        "    display_html(4, \"Anderson-Darling Test:\")\n",
        "    ad_test = stats.anderson(col.dropna().values, dist=\"norm\")\n",
        "    ad_statistic = ad_test.statistic\n",
        "    ad_critical = ad_test.critical_values[2]\n",
        "    print(f\"{'Significance Level':21}: {alpha}\")\n",
        "    print(f\"{'Null Hypothesis':21}: The data is normally distributed\")\n",
        "    print(f\"{'Alternate Hypothesis':21}: The data is not normally distributed\")\n",
        "    print(f\"{'Critical Value':21}: {ad_critical}\")\n",
        "    print(f\"{'Test Statistic':21}: {ad_statistic}\")\n",
        "    if ad_statistic >= ad_critical:\n",
        "        print(f\"- Since the Test-statistic is greater than Critical Value, we Reject the Null Hypothesis at {alpha * 100}% significance level\")\n",
        "        print(\"- CONCLUSION: We conclude that the data sample is not normally distributed\")\n",
        "    else:\n",
        "        print(f\"- Since the Test-statistic is less than Critical Value, we Fail to Reject the Null Hypothesis at {alpha * 100}% significance level\")\n",
        "        print(\"- CONCLUSION: We conclude that the data sample is normally distributed\")\n"
      ],
      "metadata": {
        "id": "NDldtHbaLxOe"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot categorical variable (univariate analysis)\n",
        "def cat_univar_plots(data, var, k=None, show_wordcloud=True, figsize=(12, 8.5)):\n",
        "    \"\"\"\n",
        "    Generates univariate visualizations for a categorical variable in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - data (pd.DataFrame): The DataFrame containing the categorical data.\n",
        "    - var (str): The name of the categorical variable to visualize.\n",
        "    - k (int, optional): If specified, only the top k categories by count are included. The rest are grouped into \"Other\".\n",
        "    - show_wordcloud (bool, optional): Whether to include a word cloud visualization. Default is True.\n",
        "    - figsize (tuple, optional): The size of the figure for the plots. Default is (12, 8.5).\n",
        "\n",
        "    Returns:\n",
        "    - None: Displays a series of plots including:\n",
        "        - A bar chart showing counts of categories.\n",
        "        - A pie chart showing the percentage distribution of categories.\n",
        "        - (Optional) A word cloud visualization of the categories.\n",
        "    \"\"\"\n",
        "    display_html(1,f\"Univariate Analysis of {var}\")\n",
        "    # Data Processing\n",
        "    col = data[var].copy()\n",
        "    if k is not None:\n",
        "        top_categories = col.value_counts().index[:k-1]\n",
        "        counts = col.where(col.isin(top_categories), \"Other\").value_counts()\n",
        "    else:\n",
        "        counts = col.value_counts()\n",
        "\n",
        "    # Random Colors\n",
        "    colors = [tuple(np.random.choice(256, size=3) / 255) for _ in range(len(counts))]\n",
        "\n",
        "    # Plotting\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    gs = GridSpec(2, 2, figure=fig)\n",
        "    ax1, ax2, ax3 = fig.add_subplot(gs[0, 0]), fig.add_subplot(gs[0, 1]), fig.add_subplot(gs[1, :])\n",
        "\n",
        "    # Bar-chart\n",
        "    ax1.bar(counts.index, counts.values, color=colors, edgecolor=\"black\", alpha=0.7)\n",
        "    ax1.bar_label(ax1.containers[0], padding=5, color=\"black\")\n",
        "    ax1.set(title=\"Bar Chart\", xlabel=\"Categories\", ylabel=\"Count\")\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # Pie-chart\n",
        "    ax2.pie(counts, labels=counts.index, autopct=\"%.2f%%\", colors=colors, wedgeprops=dict(alpha=0.7, edgecolor=\"black\"))\n",
        "    ax2.set_title(\"Pie Chart\")\n",
        "    ax2.legend(loc=\"upper left\", bbox_to_anchor=(1.02, 1), title=\"Categories\")\n",
        "\n",
        "    # Word-cloud\n",
        "    if show_wordcloud:\n",
        "        var_string = \" \".join(\n",
        "            data\n",
        "            .loc[:, var]\n",
        "            .dropna()\n",
        "            .str.replace(\" \", \".\")\n",
        "            .to_list()\n",
        "        )\n",
        "\n",
        "        word_cloud = WordCloud(\n",
        "            width=2000,\n",
        "            height=700,\n",
        "            random_state=42,\n",
        "            background_color=\"black\",\n",
        "            colormap=\"Set2\",\n",
        "            stopwords=STOPWORDS\n",
        "        ).generate(var_string)\n",
        "\n",
        "        ax3.imshow(word_cloud, interpolation=\"bilinear\")\n",
        "        ax3.axis(\"off\")\n",
        "        ax3.set_title(\"Word Cloud\")\n",
        "    else:\n",
        "        ax3.remove()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "glD4QHIjKK-b"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot categorical-numerical variable (Bivariate analysis)\n",
        "\n",
        "def num_cat_bivar_plots(df, var, num, k=None, estimator=\"mean\",rotation=90, figsize=(12,10)):\n",
        "\n",
        "    \"\"\"\n",
        "    Generate a set of bi-variate plots between a categorical variable and a numerical variable.\n",
        "\n",
        "    This function creates three plots to visualize the relationship between a categorical variable\n",
        "    (`var`) and a numerical variable (`num`):\n",
        "    1. A bar plot showing the aggregated values (mean or other estimator) of the numerical variable\n",
        "       for each category.\n",
        "    2. A boxplot illustrating the distribution of the numerical variable across the categories.\n",
        "    3. A violin plot providing a density estimate of the numerical variable for each category.\n",
        "\n",
        "    Parameters:\n",
        "        df (pandas.DataFrame): The DataFrame containing the data.\n",
        "        var (str): The name of the categorical variable.\n",
        "        num (str): The name of the numerical variable.\n",
        "        k (int, optional): The number of top categories to include. Categories beyond this number\n",
        "            will be grouped into an \"Other\" category. If `None`, all categories are used.\n",
        "        estimator (str, optional): The aggregation function to apply to the numerical variable\n",
        "            (e.g., \"mean\", \"sum\"). Default is \"mean\".\n",
        "        figsize (tuple, optional): The size of the figure. Default is (12, 10).\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    display_html(1, f\"Bi-variate Analysis between {var} and {num}\")\n",
        "\n",
        "    # Make a copy of the DataFrame to avoid modifying the original\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    # Handle top k categories if specified\n",
        "    if k is not None:\n",
        "        top_categories = df_copy[var].value_counts().index[:k-1]\n",
        "        df_copy[var] = df_copy[var].where(df_copy[var].isin(top_categories), \"Other\")  # Create \"Other\" category\n",
        "\n",
        "    # Calculate aggregated values for barplot\n",
        "    agg_df = df_copy.groupby(var)[num].agg(estimator).reset_index().sort_values(by=num, ascending=True)\n",
        "\n",
        "    # Order categories by aggregated values\n",
        "    order = agg_df[var]\n",
        "\n",
        "    # Plotting\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    gs = GridSpec(2, 2, figure=fig)\n",
        "    ax1 = fig.add_subplot(gs[0, 0])\n",
        "    ax2 = fig.add_subplot(gs[0, 1])\n",
        "    ax3 = fig.add_subplot(gs[1, :])\n",
        "\n",
        "    # Create the barplot\n",
        "    sns.barplot(data=agg_df, x=var, y=num, ax=ax1, color=\"#d92b2b\", order=order)\n",
        "    ax1.bar_label(ax1.containers[0], padding=2, color=\"black\")  # Set labels to vertical\n",
        "    ax1.set_title(f'{estimator.capitalize()} {num} by {var}')\n",
        "    ax1.tick_params(axis='x', rotation=rotation)\n",
        "\n",
        "    # Create the boxplot\n",
        "    sns.boxplot(data=df_copy, x=var, y=num, order=order, color=\"lightgreen\", ax=ax2)\n",
        "    ax2.set_title(f'Boxplot of {num} by {var}')\n",
        "    ax2.tick_params(axis='x', rotation=rotation)\n",
        "\n",
        "    # Create the violinplot\n",
        "    sns.violinplot(data=df_copy, x=var, y=num, order=order, ax=ax3)\n",
        "    ax3.set_title(f'Violinplot of {num} by {var}')\n",
        "    ax3.tick_params(axis='x', rotation=rotation)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "C3RngG18KcmJ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cat-Cat plot (Bivariate plot)\n",
        "def plot_cat_bivariate(data, var1, var2, k1=None, k2=None, order1=None, order2=None, figsize=(15, 15), xlabel_rotation=45, annot_fontsize=10):\n",
        "    \"\"\"\n",
        "    Function to perform bivariate analysis between two categorical variables,\n",
        "    generating a cross-tab heatmap, normalized heatmap, bar plot, and stacked bar plot.\n",
        "\n",
        "    Parameters:\n",
        "    data (pd.DataFrame): DataFrame containing the data\n",
        "    var1 (str): First categorical variable\n",
        "    var2 (str): Second categorical variable\n",
        "    k1 (int, optional): Top k categories to consider for var1\n",
        "    k2 (int, optional): Top k categories to consider for var2\n",
        "    order1 (list, optional): Custom order for categories of var1\n",
        "    order2 (list, optional): Custom order for categories of var2\n",
        "    figsize (tuple, optional): Figure size for the plots\n",
        "    xlabel_rotation (int, optional): Degree of rotation for x-axis labels in the bar plots\n",
        "    annot_fontsize (int, optional): Font size for annotations in the heatmap\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Function to get top k categories\n",
        "    def get_top_k(data, var, k):\n",
        "        return data[data[var].isin(data[var].value_counts().nlargest(k).index)]\n",
        "\n",
        "    # Filter top k categories if specified\n",
        "    if k1 is not None:\n",
        "        data = get_top_k(data, var1, k1)\n",
        "    if k2 is not None:\n",
        "        data = get_top_k(data, var2, k2)\n",
        "\n",
        "    # Create subplots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    # Cross-tab heatmap\n",
        "    ct = pd.crosstab(index=data[var1], columns=data[var2]).reindex(index=order1, columns=order2)\n",
        "    sns.heatmap(ct, annot=True, annot_kws={\"size\": annot_fontsize}, linewidths=2, linecolor=\"white\", square=True, cmap=\"Blues\", cbar_kws=dict(location=\"right\", label=\"Counts\"), ax=axes[0])\n",
        "    axes[0].set_title('Cross-tab Heatmap', fontsize=14)\n",
        "    axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=xlabel_rotation, ha=\"right\")\n",
        "    axes[0].set_xlabel(var2, fontsize=12)\n",
        "    axes[0].set_ylabel(var1, fontsize=12)\n",
        "\n",
        "    # Normalized cross-tab heatmap\n",
        "    norm_ct = pd.crosstab(index=data[var1], columns=data[var2], normalize=\"index\").reindex(index=order1, columns=order2)\n",
        "    sns.heatmap(norm_ct, annot=True, annot_kws={\"size\": annot_fontsize}, linewidths=2, linecolor=\"white\", square=True, cmap=\"Greens\", cbar_kws=dict(location=\"right\", label=\"Normalized\"), ax=axes[1])\n",
        "    axes[1].set_title('Normalized Cross-tab Heatmap', fontsize=14)\n",
        "    axes[1].set_xlabel(var2, fontsize=12)\n",
        "    axes[1].set_ylabel(var1, fontsize=12)\n",
        "    axes[1].set(ylabel=\"\")\n",
        "\n",
        "    # Bar plot\n",
        "    ct.plot.bar(ax=axes[2], title=\"Bar Plot\", legend=False)\n",
        "    axes[2].set_xticklabels(axes[2].get_xticklabels(), rotation=xlabel_rotation, ha=\"right\")\n",
        "    axes[2].set_xlabel(var1, fontsize=12)\n",
        "    axes[2].set_ylabel('Counts', fontsize=12)\n",
        "\n",
        "    # Stacked bar plot\n",
        "    norm_ct.plot.bar(stacked=True, ax=axes[3], title=\"Stacked Bar Plot\")\n",
        "    axes[3].set_xticklabels(axes[3].get_xticklabels(), rotation=xlabel_rotation, ha=\"right\")\n",
        "    axes[3].legend(loc=\"upper left\", bbox_to_anchor=(1, 1), title=var2)\n",
        "    axes[3].set_xlabel(var1, fontsize=12)\n",
        "    axes[3].set_ylabel('Proportion', fontsize=12)\n",
        "\n",
        "    plt.tight_layout(pad=3.0)\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "fpklF7A5NSmx"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot categorical-numerical variable (multivariate analysis)\n",
        "\n",
        "def cat_num_facetgrid(\n",
        "    data_frame, facet_column, hue_column, x_axis_column, y_axis_column, top_k=None,\n",
        "    columns_per_row=None, facet_height=4, facet_aspect_ratio=1.2, x_axis_order=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Creates a FacetGrid bar plot with optional top-k filtering for categories.\n",
        "\n",
        "    Parameters:\n",
        "    - data_frame: DataFrame containing the data.\n",
        "    - facet_column: Column name for facetting (grid columns).\n",
        "    - hue_column: Column name for hue (color).\n",
        "    - x_axis_column: Column name for x-axis.\n",
        "    - y_axis_column: Column name for y-axis.\n",
        "    - top_k: Optional integer specifying the number of top categories to display.\n",
        "    - columns_per_row: Number of facets to wrap in a row. If None, it will be auto-calculated.\n",
        "    - facet_height: Height of each facet.\n",
        "    - facet_aspect_ratio: Aspect ratio of each facet.\n",
        "    - x_axis_order: Optional list of order for x-axis categories.\n",
        "    \"\"\"\n",
        "\n",
        "    # Display a message about the analysis\n",
        "    display_html(1, f\"Multivariate Analysis between {x_axis_column}, {y_axis_column}, {facet_column} & {hue_column}:\")\n",
        "\n",
        "    # Copy the DataFrame to avoid modifying the original\n",
        "    df_copy = data_frame.copy()\n",
        "\n",
        "    # Handle top k categories for x_axis_column if specified\n",
        "    if top_k is not None:\n",
        "        top_categories = df_copy[x_axis_column].value_counts().index[:top_k]\n",
        "        df_copy[x_axis_column] = df_copy[x_axis_column].where(df_copy[x_axis_column].isin(top_categories), \"Other\")\n",
        "\n",
        "    # Determine the number of facets and auto-calculate columns_per_row if not provided\n",
        "    num_facets = df_copy[facet_column].nunique()\n",
        "    if columns_per_row is None:\n",
        "        columns_per_row = max(3, num_facets // 2)  # Ensure at least 2 columns per row\n",
        "\n",
        "    # Create the FacetGrid\n",
        "    grid = sns.FacetGrid(\n",
        "        data=df_copy,\n",
        "        col=facet_column,\n",
        "        hue=hue_column,\n",
        "        col_wrap=columns_per_row,\n",
        "        height=facet_height,\n",
        "        aspect=facet_aspect_ratio,\n",
        "        sharey=True\n",
        "    )\n",
        "\n",
        "    # Map the barplot onto the grid\n",
        "    grid.map(sns.barplot, x_axis_column, y_axis_column, order=x_axis_order, errorbar=None)\n",
        "\n",
        "    # Customize each subplot\n",
        "    for ax in grid.axes.flatten():\n",
        "        ax.legend(title=hue_column, bbox_to_anchor=(1.05, 1), loc='upper left')  # Move legend outside\n",
        "        plt.setp(ax.get_xticklabels(), rotation=90)  # Rotate x-tick labels\n",
        "\n",
        "    # Adjust the layout and display the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "yXggdfZrK0oQ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cat-Num hypothesis testing\n",
        "def num_cat_hyp_testing(df,num_var,cat_var,alpha=.05):\n",
        "    \"\"\"\n",
        "    Performs hypothesis testing to assess the association between a numerical variable and a categorical variable.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): The DataFrame containing the variables.\n",
        "    - num_var (str): The name of the numerical variable.\n",
        "    - cat_var (str): The name of the categorical variable.\n",
        "    - alpha (float, optional): The significance level for the hypothesis tests. Default is 0.05.\n",
        "\n",
        "    Returns:\n",
        "    - None: Displays the results of ANOVA and Kruskal-Wallis tests.\n",
        "    \"\"\"\n",
        "    grouped_df=[j[num_var] for i,j in df.groupby(cat_var)]\n",
        "    #ANOVA\n",
        "    statistic,pvalue=f_oneway(*grouped_df)\n",
        "\n",
        "    display_html(1,f\"Hypothesis Test for Association between {num_var} and {cat_var}\")\n",
        "    display_html(1,\"ANOVA Test\")\n",
        "    print(f\"- {'Significance Level':21}: {alpha * 100}%\")\n",
        "    print(f\"- {'Null Hypothesis':21}: The groups have similar population mean\")\n",
        "    print(f\"- {'Alternate Hypothesis':21}: The groups don't have similar population mean\")\n",
        "    print(f\"- {'Test Statistic':21}: {statistic}\")\n",
        "    print(f\"- {'p-value':21}: {pvalue}\")\n",
        "    if pvalue < alpha:\n",
        "        print(f\"- Since p-value is less than {alpha}, we Reject the Null Hypothesis at {alpha * 100}% significance level\")\n",
        "        print(f\"- CONCLUSION: The variables {num_var} and {cat_var} are associated to each other\")\n",
        "    else:\n",
        "        print(f\"- Since p-value is greater than {alpha}, we Fail to Reject the Null Hypothesis at {alpha * 100}% significance level\")\n",
        "        print(f\"- CONCLUSION: The variables {num_var} and {cat_var} are not associated to each other\")\n",
        "    # kruskal-wallis test\n",
        "    kr = kruskal(*grouped_df)\n",
        "    statistic = kr[0]\n",
        "    pvalue = kr[1]\n",
        "    display_html(3, \"Kruskal-Wallis Test\")\n",
        "    print(f\"- {'Significance Level':21}: {alpha * 100}%\")\n",
        "    print(f\"- {'Null Hypothesis':21}: The groups have similar population median\")\n",
        "    print(f\"- {'Alternate Hypothesis':21}: The groups don't have similar population median\")\n",
        "    print(f\"- {'Test Statistic':21}: {statistic}\")\n",
        "    print(f\"- {'p-value':21}: {pvalue}\")\n",
        "    if pvalue < alpha:\n",
        "        print(f\"- Since p-value is less than {alpha}, we Reject the Null Hypothesis at {alpha * 100}% significance level\")\n",
        "        print(f\"- CONCLUSION: The variables {num_var} and {cat_var} are associated to each other\")\n",
        "    else:\n",
        "        print(f\"- Since p-value is greater than {alpha}, we Fail to Reject the Null Hypothesis at {alpha * 100}% significance level\")\n",
        "        print(f\"- CONCLUSION: The variables {num_var} and {cat_var} are not associated to each other\")\n",
        ""
      ],
      "metadata": {
        "id": "FSpKGRv8K9hJ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cat-Cat hypothesis testing\n",
        "def hyp_cat_cat(data, var1, var2, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform a hypothesis test for association between two categorical variables using the Chi-square test\n",
        "    and calculate Cramér's V statistic.\n",
        "\n",
        "    Parameters:\n",
        "    data (pd.DataFrame): DataFrame containing the data.\n",
        "    var1 (str): First categorical variable.\n",
        "    var2 (str): Second categorical variable.\n",
        "    alpha (float, optional): Significance level for the test. Default is 0.05.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    display_html(2, f\"Hypothesis Test for Association between {var1} and {var2}\")\n",
        "\n",
        "    # Cross-tabulation between the two variables\n",
        "    ct = pd.crosstab(data[var1], data[var2])\n",
        "\n",
        "    # Performing the Chi-square test\n",
        "    chi2_statistic, pvalue, _, _ = stats.chi2_contingency(ct)\n",
        "\n",
        "    # Calculating Cramér's V\n",
        "    n = ct.sum().sum()\n",
        "    r, k = ct.shape\n",
        "    cramers_v = np.sqrt(chi2_statistic / (n * (min(r, k) - 1)))\n",
        "\n",
        "    # Displaying test results\n",
        "    display_html(3,\"Chi-square Test Results\")\n",
        "    print(f\"- {'Cramérs V':21}: {cramers_v:.4f}\")\n",
        "    print(f\"- {'Significance Level':21}: {alpha * 100:.2f}%\")\n",
        "    print(f\"- {'Null Hypothesis':21}: The variables are independent\")\n",
        "    print(f\"- {'Alternate Hypothesis':21}: The variables are dependent\")\n",
        "    print(f\"- {'Chi-square Statistic':21}: {chi2_statistic:.4f}\")\n",
        "    print(f\"- {'p-value':21}: {pvalue:.4f}\")\n",
        "\n",
        "    # Hypothesis conclusion\n",
        "    if pvalue < alpha:\n",
        "        print(f\"\\nConclusion: Since the p-value is less than {alpha}, we reject the null hypothesis.\")\n",
        "        print(f\"The variables {var1} and {var2} are likely associated.\")\n",
        "    else:\n",
        "        print(f\"\\nConclusion: Since the p-value is greater than {alpha}, we fail to reject the null hypothesis.\")\n",
        "        print(f\"The variables {var1} and {var2} are likely independent.\")\n"
      ],
      "metadata": {
        "id": "ogG3EBuoLIHP"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Date_Time analysis:\n",
        "def dt_univariate_plot(df, var, parm=None, bin=\"auto\",fig=(12, 4)):\n",
        "    \"\"\"\n",
        "    Performs univariate analysis of a datetime variable and visualizes its distribution.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): The DataFrame containing the datetime variable.\n",
        "    - var (str): The name of the datetime variable.\n",
        "    - parm (str, optional): A string specifying the datetime attribute to extract. E.g., 'dt.year', 'dt.month'.\n",
        "    - bin (int or 'auto', optional): Number of bins for the histogram. Default is 'auto'.\n",
        "    - fig (tuple, optional): Size of the figure. Default is (12, 4).\n",
        "\n",
        "    Returns:\n",
        "    - None: Displays the histogram with a rug plot and a line plot.\n",
        "    \"\"\"\n",
        "    # Extract datetime attribute if parm is provided\n",
        "    if parm:\n",
        "        if parm == 'dt.isocalendar().week':\n",
        "            extracted_data = df[var].dt.isocalendar().week\n",
        "        else:\n",
        "            accessor, attribute = parm.split(\".\")\n",
        "            if accessor != 'dt':\n",
        "                raise ValueError(\"Invalid accessor. Only 'dt' accessor is supported.\")\n",
        "            if attribute.endswith(\"()\"):\n",
        "                attribute = attribute[:-2]  # Remove '()'\n",
        "                extracted_data = getattr(df[var].dt, attribute)()\n",
        "            else:\n",
        "                extracted_data = getattr(df[var].dt, attribute)\n",
        "    else:\n",
        "        extracted_data = df[var]\n",
        "\n",
        "    # Create figure and subplots\n",
        "    fig, ax = plt.subplots(1, 2, figsize=fig)\n",
        "\n",
        "    # Histogram with rug plot\n",
        "    sns.histplot(extracted_data, kde=False, color='skyblue', bins=bin, ax=ax[0])\n",
        "    sns.rugplot(x=extracted_data, color='black', ax=ax[0])\n",
        "    ax[0].set_xlabel(var)\n",
        "    ax[0].set_ylabel('Count')\n",
        "    ax[0].set_title('Histogram with Rug Plot')\n",
        "    ax[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    ax[0].bar_label(ax[0].containers[0], padding=3, color=\"black\")\n",
        "\n",
        "    # Line plot\n",
        "    journey_counts = extracted_data.value_counts().sort_index()\n",
        "\n",
        "    sns.lineplot(x=journey_counts.index, y=journey_counts.values, color=\"#d92b2b\", ax=ax[1])\n",
        "    ax[1].set_xlabel(var)\n",
        "    ax[1].set_ylabel('Frequency')\n",
        "    ax[1].set_title('Line Plot')\n",
        "    ax[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hLedh1N3L-Sc"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def assign_time_of_day(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Adds a new column to the DataFrame that categorizes the departure times into different parts of the day.\n",
        "\n",
        "    The new column `dep_time_of_day` is created based on the hour of the day from the `dep_time` column.\n",
        "    The times are categorized as follows:\n",
        "    - \"morning\": 04:00 to 12:00 (inclusive)\n",
        "    - \"afternoon\": 12:01 to 16:00 (inclusive)\n",
        "    - \"evening\": 16:01 to 20:00 (inclusive)\n",
        "    - \"night\": 20:01 to 03:59 (default for times not covered by the above ranges)\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        The input DataFrame containing a datetime column `dep_time`.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        The modified DataFrame with the new column `dep_time_of_day`.\n",
        "    \"\"\"\n",
        "    df = df.assign(\n",
        "        dep_time_of_day=lambda df_: np.select(\n",
        "            [df_.dep_time.dt.hour.between(4, 12, inclusive=\"left\"),\n",
        "             df_.dep_time.dt.hour.between(12, 16, inclusive=\"left\"),\n",
        "             df_.dep_time.dt.hour.between(16, 20, inclusive=\"left\")],\n",
        "            [\"morning\", \"afternoon\", \"evening\"],\n",
        "            default=\"night\"\n",
        "        )\n",
        "    )\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "DkLHgrsBMZrL"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dt_multivatirate_plot(data,dt_var,cat_var,num_var):\n",
        "    \"\"\"\n",
        "    Creates a bar plot to visualize the mean of a numerical variable across different months\n",
        "    for each category.\n",
        "\n",
        "    Parameters:\n",
        "    - data (pd.DataFrame): The DataFrame containing the variables.\n",
        "    - dt_var (str): The name of the datetime variable.\n",
        "    - cat_var (str): The name of the categorical variable.\n",
        "    - num_var (str): The name of the numerical variable.\n",
        "\n",
        "    Returns:\n",
        "    - None: Displays a bar plot.\n",
        "    \"\"\"\n",
        "    data=df.groupby([dt_var, cat_var]).agg({\n",
        "        # Changed num_var to price as destination is a categorical variable not numerical\n",
        "        num_var: 'mean',\n",
        "        dt_var: lambda x: x.dt.month_name().iloc[0]\n",
        "    }).reset_index(names=['date', cat_var, num_var, 'month']).iloc[:,1:]\n",
        "\n",
        "    sns.barplot(data, x=dt_var, y=num_var, hue=cat_var,errorbar=None) # Changed num_var to price\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "bq_o4OS7ML1t"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dt_multivariate_plot(df, dt_var, cat_var, num_var, parm=None, fig=(11.5, 6),rotate=45):\n",
        "    \"\"\"\n",
        "    Creates a bar plot to visualize the mean of a numerical variable across different datetime\n",
        "    attributes and categories.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): The DataFrame containing the variables.\n",
        "    - dt_var (str): The name of the datetime variable.\n",
        "    - cat_var (str): The name of the categorical variable.\n",
        "    - num_var (str): The name of the numerical variable.\n",
        "    - parm (str, optional): A datetime accessor attribute. Default is None.\n",
        "    - fig (tuple, optional): Size of the figure. Default is (11.5, 6).\n",
        "    - rotate (int, optional): Rotation angle for x-axis labels. Default is 45.\n",
        "\n",
        "    Returns:\n",
        "    - None: Displays a bar plot.\n",
        "    \"\"\"\n",
        "    df=df.copy()\n",
        "    # Display a message about the analysis\n",
        "    display_html(1, f\"Multivariate Analysis between {dt_var}, {cat_var} & {num_var}:\")\n",
        "    # Handle datetime accessor if provided in parm\n",
        "    if parm:\n",
        "        if parm == 'dt.isocalendar().week':\n",
        "            df['processed_dt_var'] = df[dt_var].dt.isocalendar().week\n",
        "        else:\n",
        "            accessor, attribute = parm.split(\".\")\n",
        "            if accessor != 'dt':\n",
        "                raise ValueError(\"Invalid accessor. Only 'dt' accessor is supported.\")\n",
        "            if attribute.endswith(\"()\"):\n",
        "                attribute = attribute[:-2]  # Remove '()'\n",
        "                df['processed_dt_var'] = getattr(df[dt_var].dt, attribute)()\n",
        "            else:\n",
        "                df['processed_dt_var'] = getattr(df[dt_var].dt, attribute)\n",
        "    else:\n",
        "        df['processed_dt_var'] = df[dt_var]\n",
        "\n",
        "    # Group data by processed datetime and categorical variable\n",
        "    grouped_data = df.groupby(['processed_dt_var', cat_var]).agg({num_var: 'mean'}).reset_index()\n",
        "\n",
        "    # Plot the bar plot\n",
        "    plt.figure(figsize=fig)\n",
        "    sns.barplot(data=grouped_data, x='processed_dt_var', y=num_var, hue=cat_var, errorbar=None)\n",
        "    plt.xlabel(dt_var if parm is None else f'{dt_var} ({parm})')\n",
        "    plt.ylabel(f'Mean {num_var}')\n",
        "    plt.title(f'Mean {num_var} by {cat_var} and {dt_var}')\n",
        "\n",
        "    # Adjust legend and layout\n",
        "    plt.gca().legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
        "    plt.xticks(rotation=rotate)\n",
        "    plt.tight_layout(rect=[0, 0, 1.2, 1.1])\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZCdY7rUBMNnw"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Numerical variable (univariate analysis)\n",
        "def num_univar_plots(df, column_name, bin=\"auto\", fig_size=(12, 10)):\n",
        "    \"\"\"\n",
        "    Creates various univariate plots for analyzing the distribution of a numerical variable.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): The DataFrame containing the data.\n",
        "    - column_name (str): The name of the numerical column to analyze.\n",
        "    - bin (int or 'auto', optional): Number of bins for the histogram. Default is 'auto'.\n",
        "    - fig_size (tuple, optional): Size of the figure. Default is (12, 10).\n",
        "\n",
        "    Returns:\n",
        "    - None: Displays the plots.\n",
        "    \"\"\"\n",
        "\n",
        "    # Display a message about the analysis\n",
        "    display_html(1,f\"Distribution of {column_name}:\")\n",
        "    print()\n",
        "    # Setup the figure and GridSpec\n",
        "    fig = plt.figure(figsize=fig_size)\n",
        "    gs = GridSpec(3, 2, height_ratios=[2, 2, 2])\n",
        "\n",
        "    # Histogram with KDE & Rug plot\n",
        "    ax0 = fig.add_subplot(gs[0, 0])\n",
        "    sns.histplot(df[column_name], kde=True, color=\"orange\", bins=bin, ax=ax0)\n",
        "    sns.rugplot(df[column_name],color=\"black\",ax=ax0)\n",
        "    ax0.set_title(\"Histogram with KDE & Rug plot\")\n",
        "    ax0.set_xlabel(column_name)\n",
        "    ax0.set_ylabel(\"Frequency\")\n",
        "\n",
        "    # ECDF Plot\n",
        "    ax1 = fig.add_subplot(gs[0, 1])\n",
        "    sns.ecdfplot(df[column_name], color=\"red\", ax=ax1)\n",
        "    ax1.set_title(\"ECDF Plot\")\n",
        "    ax1.set_xlabel(column_name)\n",
        "    ax1.set_ylabel(\"ECDF\")\n",
        "\n",
        "    # Box Plot\n",
        "    ax2 = fig.add_subplot(gs[1, 0])\n",
        "    sns.boxplot(x=df[column_name], color=\"green\", ax=ax2)\n",
        "    ax2.set_title(\"Box Plot\")\n",
        "    ax2.set_xlabel(column_name)\n",
        "\n",
        "    # Violin Plot\n",
        "    ax3 = fig.add_subplot(gs[1, 1])\n",
        "    sns.violinplot(x=df[column_name], color=\"purple\", ax=ax3)\n",
        "    ax3.set_title(\"Violin Plot\")\n",
        "    ax3.set_xlabel(column_name)\n",
        "\n",
        "    # Q-Q Plot\n",
        "    ax4 = fig.add_subplot(gs[2, :])\n",
        "    stats.probplot(df[column_name], dist=\"norm\", plot=ax4)\n",
        "    ax4.set_title(\"Q-Q Plot\")\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "cvALfOC6MQZM"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformation Plot for numerical variable\n",
        "def transformation_plot(df, column_name):\n",
        "    \"\"\"\n",
        "    Creates a set of plots to analyze the effects of different data transformations on a numerical variable.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): The DataFrame containing the data.\n",
        "    - column_name (str): The name of the numerical column to analyze.\n",
        "\n",
        "    Returns:\n",
        "    - None: Displays the plots.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define a function to create a Q-Q plot\n",
        "    def qq_plot(data, ax, title):\n",
        "        \"\"\"Creates a Q-Q plot.\"\"\"\n",
        "        stats.probplot(data, dist=\"norm\", plot=ax)\n",
        "        ax.get_lines()[1].set_color('red')  # Change color of the Q-Q line\n",
        "        ax.set_title(title, fontsize=16)\n",
        "        ax.get_xaxis().set_tick_params(labelsize=12)\n",
        "        ax.get_yaxis().set_tick_params(labelsize=12)\n",
        "\n",
        "    # Display a message about the analysis\n",
        "    display_html(1, f\"Transformation Plot for {column_name}:\")\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # Creating transformed columns\n",
        "    df['log_' + column_name] = np.log(df[column_name] + 0.001)\n",
        "    df['sqrt_' + column_name] = np.sqrt(df[column_name] + 0.001)\n",
        "\n",
        "    # Yeo-Johnson Transformation\n",
        "    pt_yj = PowerTransformer(method='yeo-johnson')\n",
        "    df['yeojohnson_' + column_name] = pt_yj.fit_transform(df[column_name].values.reshape(-1, 1))\n",
        "\n",
        "    # Box-Cox Transformation with three conditions\n",
        "    boxcox_transformed = False\n",
        "    if (df[column_name] > 0).all():\n",
        "        # Positive values\n",
        "        pt_bc = PowerTransformer(method='box-cox')\n",
        "        df['boxcox_' + column_name] = pt_bc.fit_transform(df[column_name].values.reshape(-1, 1))\n",
        "        boxcox_transformed = True\n",
        "    elif (df[column_name] == 0).any():\n",
        "        # Zero values\n",
        "        df['boxcox_' + column_name] = pt_bc.fit_transform((df[column_name]+0.001).values.reshape(-1, 1))\n",
        "        boxcox_transformed = True\n",
        "    else:\n",
        "        # Negative values\n",
        "        df['boxcox_' + column_name] = np.nan  # Set to NaN if not applicable\n",
        "\n",
        "    # Plotting\n",
        "    fig, axes = plt.subplots(5, 2, figsize=(18, 24))  # Layout for side-by-side plots\n",
        "\n",
        "    # Original Data\n",
        "    sns.histplot(df[column_name], kde=True, color=\"blue\", ax=axes[0, 0])\n",
        "    sns.rugplot(x=df[column_name], color=\"black\", ax=axes[0, 0])\n",
        "    axes[0, 0].set_title(\"Original Data - Histogram\", fontsize=16)\n",
        "    qq_plot(df[column_name], axes[0, 1], \"Q-Q Plot - Original Data\")\n",
        "\n",
        "    # Log Transformation\n",
        "    sns.histplot(df['log_' + column_name], kde=True, color=\"green\", ax=axes[1, 0])\n",
        "    sns.rugplot(x=df['log_' + column_name], color=\"black\", ax=axes[1, 0])\n",
        "    axes[1, 0].set_title(\"Log Transformation - Histogram\", fontsize=16)\n",
        "    qq_plot(df['log_' + column_name], axes[1, 1], \"Q-Q Plot - Log Transformation\")\n",
        "\n",
        "    # Square Root Transformation\n",
        "    sns.histplot(df['sqrt_' + column_name], kde=True, color=\"red\", ax=axes[2, 0])\n",
        "    sns.rugplot(x=df['sqrt_' + column_name], color=\"black\", ax=axes[2, 0])\n",
        "    axes[2, 0].set_title(\"Square Root Transformation - Histogram\", fontsize=16)\n",
        "    qq_plot(df['sqrt_' + column_name], axes[2, 1], \"Q-Q Plot - Square Root Transformation\")\n",
        "\n",
        "    # Box-Cox Transformation\n",
        "    if boxcox_transformed:\n",
        "        sns.histplot(df['boxcox_' + column_name], kde=True, color=\"orange\", ax=axes[3, 0])\n",
        "        sns.rugplot(x=df['boxcox_' + column_name], color=\"black\", ax=axes[3, 0])\n",
        "        axes[3, 0].set_title(\"Box-Cox Transformation - Histogram\", fontsize=16)\n",
        "        qq_plot(df['boxcox_' + column_name], axes[3, 1], \"Q-Q Plot - Box-Cox Transformation\")\n",
        "    else:\n",
        "        # Remove the Box-Cox subplot if transformation is not applicable\n",
        "        axes[3, 0].remove()\n",
        "        axes[3, 1].remove()\n",
        "\n",
        "    # Yeo-Johnson Transformation\n",
        "    sns.histplot(df['yeojohnson_' + column_name], kde=True, color=\"purple\", ax=axes[4, 0])\n",
        "    sns.rugplot(x=df['yeojohnson_' + column_name], color=\"black\", ax=axes[4, 0])\n",
        "    axes[4, 0].set_title(\"Yeo-Johnson Transformation - Histogram\", fontsize=16)\n",
        "    qq_plot(df['yeojohnson_' + column_name], axes[4, 1], \"Q-Q Plot - Yeo-Johnson Transformation\")\n",
        "\n",
        "    # Adjust subplot spacing\n",
        "    plt.subplots_adjust(wspace=0.3, hspace=0.4)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ogNY3GHKMzcC"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bivariate plots between 2 numeric variables\n",
        "def num_bivar_plots(data, var_x, var_y, figsize=(12, 4.5), scatter_kwargs=dict(), hexbin_kwargs=dict()):\n",
        "    \"\"\"\n",
        "    Creates bivariate plots between two numeric variables.\n",
        "\n",
        "    Parameters:\n",
        "    - data (pd.DataFrame): The DataFrame containing the numeric variables.\n",
        "    - var_x (str): The name of the variable to be plotted on the x-axis.\n",
        "    - var_y (str): The name of the variable to be plotted on the y-axis.\n",
        "    - figsize (tuple, optional): The size of the figure. Defaults to (12, 4.5).\n",
        "    - scatter_kwargs (dict, optional): Additional keyword arguments to pass to the scatter plot.\n",
        "    - hexbin_kwargs (dict, optional): Additional keyword arguments to pass to the hexbin plot.\n",
        "\n",
        "    Returns:\n",
        "    - None: Displays the scatter and hexbin plots.\n",
        "    \"\"\"\n",
        "    display_html(2, f\"Bi-variate Analysis between {var_x} and {var_y}\")\n",
        "    display_html(content=\"\")\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
        "\n",
        "    # scatter plot\n",
        "    sns.scatterplot(\n",
        "        data,\n",
        "        x=var_x,\n",
        "        y=var_y,\n",
        "        ax=axes[0],\n",
        "        edgecolors=\"black\",\n",
        "        **scatter_kwargs\n",
        "    )\n",
        "    axes[0].set(title=\"Scatter Plot\")\n",
        "\n",
        "    # hexbin plot\n",
        "    col_x = data.loc[:, var_x]\n",
        "    col_y = data.loc[:, var_y]\n",
        "    hexbin = axes[1].hexbin(\n",
        "        x=col_x,\n",
        "        y=col_y,\n",
        "        **hexbin_kwargs\n",
        "    )\n",
        "    axes[1].set(\n",
        "        title=\"Hexbin Plot\",\n",
        "        xlabel=var_x,\n",
        "        xlim=(col_x.min(), col_x.max()),\n",
        "        ylim=(col_y.min(), col_y.max())\n",
        "    )\n",
        "    cb = plt.colorbar(\n",
        "        hexbin,\n",
        "        label=\"Count\"\n",
        "    )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "J_7EHpfdNBLD"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Multivariate plots between 2 numeric and 2 categorical variables**\n"
      ],
      "metadata": {
        "id": "BK19MFpZNM-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def  num_cat_facetgrid(data_frame, facet_column, hue_column, x_axis_column, y_axis_column,\n",
        "    columns_per_row=None, facet_height=3, facet_aspect_ratio=1.2 ):\n",
        "    \"\"\"\n",
        "    Creates a FacetGrid of scatter plots to visualize the relationship between numeric and categorical variables.\n",
        "\n",
        "    Parameters:\n",
        "    - data_frame (pd.DataFrame): The DataFrame containing the data.\n",
        "    - facet_column (str): The name of the categorical column used to create facets (columns) in the grid.\n",
        "    - hue_column (str): The name of the categorical column used to color the points in the scatter plot.\n",
        "    - x_axis_column (str): The name of the numeric column to be plotted on the x-axis.\n",
        "    - y_axis_column (str): The name of the numeric column to be plotted on the y-axis.\n",
        "    - columns_per_row (int, optional): Number of columns in each row of facets. Defaults to auto-calculate based on the number of unique facets.\n",
        "    - facet_height (float, optional): Height of each facet in inches. Defaults to 3.\n",
        "    - facet_aspect_ratio (float, optional): Aspect ratio (height/width) of each facet. Defaults to 1.2.\n",
        "\n",
        "    Returns:\n",
        "    - None: Displays the FacetGrid of scatter plots.\n",
        "    \"\"\"\n",
        "    # Create a copy of the DataFrame to avoid modifying the original\n",
        "    df_copy= data_frame.copy()\n",
        "    # Determine the number of facets and auto-calculate columns_per_row if not provided\n",
        "    num_facets = df_copy[facet_column].nunique()\n",
        "\n",
        "    if columns_per_row is None:\n",
        "        columns_per_row = max(3, num_facets // 2)  # Ensure at least 3 columns per row\n",
        "\n",
        "    g = sns.FacetGrid(\n",
        "        df, col=facet_column, hue=hue_column, col_wrap=columns_per_row, sharex=True, sharey=True, height=facet_height, aspect=facet_aspect_ratio\n",
        "    )\n",
        "    g.map(sns.scatterplot, x_axis_column, y_axis_column)\n",
        "\n",
        "    # Add a legend to each facet\n",
        "    for ax in g.axes.flatten():\n",
        "        ax.legend(loc='best')  # Adjust the `loc` parameter as needed\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "w0ZxXP1eNJyw"
      },
      "execution_count": 67,
      "outputs": []
    }
  ]
}